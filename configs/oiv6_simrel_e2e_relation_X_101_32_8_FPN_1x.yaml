INPUT:
  MIN_SIZE_TRAIN: (600,)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
MODEL:
  META_ARCHITECTURE: "SimrelRCNN" #"GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
  RELATION_ON: True
  ATTRIBUTE_ON: False
  FLIP_AUG: False            # if there is any left-right relation, FLIP AUG should be false
  RPN:
    USE_FPN: True
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)   # from neural-motifs
    PRE_NMS_TOP_N_TRAIN: 6000
    PRE_NMS_TOP_N_TEST: 6000
    POST_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_PER_BATCH: False
    RPN_MID_CHANNEL: 256
  ROI_HEADS:
    USE_FPN: True
    POSITIVE_FRACTION: 0.5
    BG_IOU_THRESHOLD: 0.3
    BATCH_SIZE_PER_IMAGE: 256
    DETECTIONS_PER_IMG: 80
    NMS_FILTER_DUPLICATES: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 602
    MLP_HEAD_DIM: 256 #4096
  ROI_ATTRIBUTE_HEAD:
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    USE_BINARY_LOSS: True           # choose binary, because cross_entropy loss deteriorate the box head, even with 0.1 weight
    POS_WEIGHT: 50.0
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    NUM_ATTRIBUTES: 201             # 201 for VG, 501 for GQA
    MAX_ATTRIBUTES: 10             
    ATTRIBUTE_BGFG_SAMPLE: True    
    ATTRIBUTE_BGFG_RATIO: 3        
  ROI_RELATION_HEAD:
    USE_GT_BOX: False #True
    USE_GT_OBJECT_LABEL: False #True
    REQUIRE_BOX_OVERLAP: False              # for sgdet, during training, only train pairs with overlap
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True    # for sgdet only, in case some gt boxes are missing
    NUM_CLASSES: 31                 # 51 for VG, 201 for GQA (not contain "to the left of" & "to the right of")
    BATCH_SIZE_PER_IMAGE: 1024      # sample as much as possible
    POSITIVE_FRACTION: 0.25
    CONTEXT_POOLING_DIM: 256 #4096
    CONTEXT_HIDDEN_DIM: 512         #1024 for VCTree
    POOLING_ALL_LEVELS: True
    LABEL_SMOOTHING_LOSS: False
    FEATURE_EXTRACTOR: "RelationFeatureExtractor"
    #################### Select Relationship Model ####################
    #PREDICTOR: "MotifPredictor"
    #PREDICTOR: "VCTreePredictor"
    #PREDICTOR: "TransformerPredictor"
    PREDICTOR: "CausalAnalysisPredictor"
    ################# Parameters for Motif Predictor ##################
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_REL_LAYER: 1
    ############# Parameters for Causal Unbias Predictor ##############
    ### Implementation for paper "Unbiased Scene Graph Generation from Biased Training"
    CAUSAL:
      EFFECT_TYPE: 'none'             # candicates: 'TDE', 'NIE', 'TE', 'none'
      FUSION_TYPE: 'sum'              # candicates: 'sum', 'gate'         
      SEPARATE_SPATIAL: False         # separate spatial in union feature
      CONTEXT_LAYER: "motifs"         # candicates: motifs, vctree, vtranse
      SPATIAL_FOR_VISION: True
      EFFECT_ANALYSIS: True
    ############### Parameters for Transformer Predictor ##############
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      OBJ_LAYER: 4
      REL_LAYER: 2
      NUM_HEAD: 8
      KEY_DIM: 64
      VAL_DIM: 64
      INNER_DIM: 2048
    LONGTAIL_PART_DICT: [None, 'h', 'h', 'h', 't', 'b', 't', 't', 'h', 'h', 'b', 't', 't', 't', 'b', 't', 't',
                                'h', 't', 'b', 't', 'b', 'b', 't', 't', 'b', 't', 'b', 't', 'h', 't']
    REL_PROP: [0.3306489557034657, 0.09472687629102594, 0.2945059674087675, 0.0006885471654808355, 
                0.0038214367684186366, 0.0005422308928161579, 0.00019221941703006655, 0.09950654119807206, 
                0.03506713334863438, 0.009926554969015377, 0.0008233876520541657, 0.00027541886619233415, 
                2.8689465228368144e-05, 0.011234794583428964, 0.00023525361487261877, 3.1558411751204955e-05, 
                0.05780640348863897, 0.00024959834748680286, 0.005155496901537755, 3.1558411751204955e-05, 
                0.012026623823731925, 0.0057034656873995865, 0.00043321092494835896, 0.00015492311223318797, 
                0.0027254991966949734, 6.311682350240991e-05, 0.0015033279779664906, 0.00021517098921276106, 
                0.031217007114987375, 0.0004590314436538903]
  SimrelRCNN:
    TRAIN_OBJ: True
    CROSS_OBJ_FEAT_FUSION: True
    USE_HUNGARIAN_LOSS: True
    USE_RELATION_FUSION_FOR_OBJECT: True
    SIAMESE_HEAD: False
DATASETS:
  TRAIN: ("openimage_v6_train",)
  VAL: ("openimage_v6_val",)
  TEST: ("openimage_v6_test",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BIAS_LR_FACTOR: 1
  BASE_LR: 0.000002 ##0.01
  WARMUP_FACTOR: 0.01 ##0.1
  WARMUP_ITERS: 1000 ##
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001 ###0.01
  MOMENTUM: 0.9
  GRAD_NORM_CLIP: 5.0
  STEPS: (47000, 64000)
  MAX_ITER: 70000
  VAL_PERIOD: 12000 #4000 #50000 #2000
  CHECKPOINT_PERIOD: 24000 #16000 #2000
  PRINT_GRAD_FREQ: 12000 #4000
  SCHEDULE:
    # the following paramters are only used for WarmupReduceLROnPlateau
    TYPE: WarmupMultiStepLR    #WarmupMultiStepLR #"WarmupReduceLROnPlateau"
    PATIENCE: 2
    THRESHOLD: 0.001
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 16 #3
  OPTIMIZER: "ADAMW"
OUTPUT_DIR: './output/relation_baseline'
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  RELATION:
    SYNC_GATHER: True      # turn on will slow down the evaluation to solve the sgdet test out of memory problem
    REQUIRE_OVERLAP: False
    LATER_NMS_PREDICTION_THRES: 0.5
  CUSTUM_EVAL: False       # eval SGDet model on custum images, output a json
  CUSTUM_PATH: '.'         # the folder that contains the custum images, only jpg files are allowed  
